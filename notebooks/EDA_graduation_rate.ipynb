{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the features in this data?\n",
    "* Each instance is a school.\n",
    "\n",
    "## Graduation rate is given by two features--Cohort and Rate--for each subpopulation below.\n",
    "* Cohort - Number of students in that subpopulation\n",
    "* Rate - Percentage (or range of percentage) of students in the cohort graduating with a high school diploma within 4 years\n",
    "\n",
    "## School identifiers\n",
    "* STNAM  - State name\n",
    "* FIPST  - 2 digit code for the state\n",
    "* LEANM  - School district name\n",
    "* LEAID  - 7 digit code for school district \n",
    "* SCHNAM - School name\n",
    "* NCESSH - 12 digit school id (only unique identifier for a school)\n",
    "\n",
    "\n",
    "## Subpopulations\n",
    "* ALL \t= All students in the school\n",
    "* MAM \t= American Indian/Alaska   Native students\n",
    "* MAS \t= Asian/Pacific Islander students\n",
    "* MHI \t= Hispanic students\n",
    "* MBL \t= Black students\n",
    "* MWH \t= White students\n",
    "* MTR \t= Two or More Races\n",
    "* CWD \t= Children with Disabilities (IDEA)\n",
    "* ECD \t= Economically Disadvantaged students\n",
    "* LEP \t= Limited English Proficient students\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from swampy import structshape as ss\n",
    "import boto3\n",
    "import shelve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest raw data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_raw_gr_frame(year):\n",
    "    \"\"\"Create raw graduation rate dataframe for a given year from S3. It is 'raw' because\n",
    "    no modifications are done and it is cached locally as-is.\"\"\"\n",
    "    conn = boto3.client('s3')\n",
    "\n",
    "    # Graduation rate raw data filenames on S3\n",
    "    year_to_loc = {2018 : \"grad_rate/acgr-sch-sy2018-19-wide.csv\",\n",
    "        2017 : \"grad_rate/acgr-sch-sy2017-18.csv\",\n",
    "        2016 : \"grad_rate/acgr-sch-sy2016-17.csv\", \n",
    "        2015 : \"grad_rate/acgr-sch-sy2015-16.csv\",\n",
    "        2014 : \"grad_rate/acgr-release2-sch-sy2014-15.csv\",\n",
    "        2013 : \"grad_rate/acgr-sch-sy2013-14.csv\",\n",
    "        2012 : \"grad_rate/acgr-sch-sy2012-13.csv\",\n",
    "        2011 : \"grad_rate/acgr-sch-sy2011-12.csv\",\n",
    "        2010 : \"grad_rate/acgr-sch-sy2010-11.csv\"}\n",
    "    \n",
    "    # Verify input parameter is valid\n",
    "    if year not in list(range(2010, 2019)):\n",
    "        raise ValueError(\"input parameter {} is out of range.\".format(year))\n",
    "\n",
    "    # Local storage (cache) for the raw data so that iteration time is faster.\n",
    "    shelf = shelve.open(\"gr_dfs\")\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    shelf_key = str(year)\n",
    "\n",
    "    if shelf_key in shelf:\n",
    "        df = shelf[shelf_key]\n",
    "    else:\n",
    "        tmp_file_name = 'curr_file.csv.bak' \n",
    "        conn.download_file('edu-data-bucket',year_to_loc[year],tmp_file_name)\n",
    "\n",
    "        df = pd.read_csv(tmp_file_name)\n",
    "        shelf[shelf_key] = df\n",
    "\n",
    "        if os.path.exists(tmp_file_name):\n",
    "            os.remove(tmp_file_name)\n",
    "\n",
    "    # Shelve teardown\n",
    "    shelf.close()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_string(y: int):\n",
    "    \"\"\"Input an integer year and get a range that matches the column suffixes in the raw data.\n",
    "    e.g. 2011 => 1112 and 2018 => 1819.\"\"\"\n",
    "    return str(y)[-2:] + str(int(str(y)[-2:]) + 1)\n",
    "\n",
    "\n",
    "dfs = [make_raw_gr_frame(year=y) for y in range(2010, 2019)]\n",
    "years = [year_string(y) for y in range(2010, 2019)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Many of the column names have the school year in them, which presents a challenge for combining all the years\n",
    "# into one large dataframe.\n",
    "print(dfs[0].columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping the data from different years to so that they can be combined into one large dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_data = [(school_year, df.shape) for school_year, df in zip(years, dfs)]\n",
    "shape = pd.DataFrame(shape_data, columns=('school_year', 'shape'))\n",
    "shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect features that are present in some but not common to all.\n",
    "# Start by removing the years from the column names.\n",
    "# cols_wo_year => Column names without the year\n",
    "cols_wo_year = [list(map(lambda x: x.replace(y, \"\"), df.columns))\n",
    "                for y, df in zip(years, dfs)]\n",
    "print(set(cols_wo_year[3]) - set(cols_wo_year[0]))\n",
    "print(set(cols_wo_year[6]) - set(cols_wo_year[0]))\n",
    "print(set(cols_wo_year[7]) - set(cols_wo_year[0]))\n",
    "print(set(cols_wo_year[8]) - set(cols_wo_year[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT_DATE refers to when the data was inserted and is not relevant for our study.\n",
    "dfs[3].drop(['INSERT_DATE'], axis=1, inplace=True)\n",
    "# ST_SCHID and ST_LEAID are values assigned by the state which are not found in the other years. From the data, it looks like maybe these\n",
    "# started being assigned in 2016. If we need another geographical grouping mechanism in the future we can look into it.\n",
    "dfs[6].drop(['ST_LEAID', 'ST_SCHID'], axis=1, inplace=True)\n",
    "# HOM_COHORT and FCS_COHORT refer to the subpopulation of homeless and foster care students, which was not tracked before school year 2017-2018\n",
    "idx7_sr = shape.school_year[7]\n",
    "idx8_sr = shape.school_year[8]\n",
    "dfs[7].drop(['ST_LEAID', 'ST_SCHID', 'FCS_RATE_'+idx7_sr, 'FCS_COHORT_'+idx7_sr,\n",
    "            'HOM_RATE_'+idx7_sr, 'HOM_COHORT_'+idx7_sr], axis=1, inplace=True)\n",
    "dfs[8].drop(['ST_LEAID', 'ST_SCHID', 'FCS_RATE_'+idx8_sr, 'FCS_COHORT_'+idx8_sr,\n",
    "            'HOM_RATE_'+idx8_sr, 'HOM_COHORT_'+idx8_sr], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify that all dataframes have the same columns before we combine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_wo_school_year = [list(map(lambda x: x.replace(y, \"\"), df.columns))\n",
    "                       for y, df in zip(years, dfs)]\n",
    "for num1, num2 in zip(range(0, 8), range(1, 9)):\n",
    "    assert cols_wo_school_year[num1] == cols_wo_school_year[num2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df = pd.DataFrame()\n",
    "print(\"big_df_columns\", big_df.columns)\n",
    "for idx, df in enumerate(dfs):\n",
    "    df.columns = cols_wo_school_year[0]\n",
    "    df['Year'] = list(range(2010,2019))[idx]\n",
    "    # reorder columns to be how we want\n",
    "    df = df[['Year']+cols_wo_school_year[0]]\n",
    "    big_df = pd.concat([big_df, df], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.shape, big_df.head(n=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How are missing values distributed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = pd.DataFrame(columns=['% Null', '% Unique'])\n",
    "df_info['% Null'] = big_df.isnull().sum() / len(big_df) * 100\n",
    "df_info['% Unique'] = big_df.nunique() / len(big_df) * 100\n",
    "df_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(big_df.columns.size),\n",
    "         (big_df.isnull().sum() / len(big_df) * 100).values)\n",
    "plt.xticks(ticks=list(range(big_df.columns.size)),\n",
    "           labels=big_df.columns.tolist(), rotation=90)\n",
    "plt.ylabel('% Null')\n",
    "# MAMs, MAS, LEP, and MTR are the subpopulations with the largest number of missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The missing data in the subpopulation columns presents a problem for performing machine learning on this data.\n",
    "* The Adjusted Cohort Graduation Rate codebook gives the following Q&A:\n",
    "#### Why doesn’t the summation of the major racial and ethnic groups equal the “ALL” student count?\n",
    "* Due to flexibilities with states’ implementation of the Elementary and Secondary Education Act,\n",
    "  there may be instances where not all possible groupings of racial/ethnic identification are reported\n",
    "  as individual subgroups. Therefore, some information may be missing and these counts by major racial\n",
    "  and ethnic group will not include every student; however any students not included within an individual\n",
    "  major racial and ethnic group would be included in the “ALL” student count.\n",
    "#### Why are the major racial and ethnic groups reported differently by states?\n",
    "* Under the ESEA, a State educational agency (SEA) has the flexibility to determine the major racial/ethnic\n",
    "  groups it will use for reporting on the data included in its assessment and accountability system.  The\n",
    "  subgroups that an SEA uses are approved through its Accountability Workbook (the most recent copy of each\n",
    "  state’s workbook can be found here:  http://www2.ed.gov/admins/lead/account/stateplans03/index.html).\n",
    "  As a result, there is some variation in how SEAs report data by race and ethnicity. \n",
    "### As a first step, we are going to look at prediction models which do not include minority groupings of the students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop population subgroup columns\n",
    "cols_to_keep = ['Year', 'STNAM', 'FIPST', 'LEAID', 'LEANM',\n",
    "                'NCESSCH', 'SCHNAM', 'ALL_COHORT_', 'ALL_RATE_']\n",
    "big_df = big_df[cols_to_keep]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature pre-processing\n",
    "* Year, ALL_COHORT_, and ALL_RATE_ are numeric columns which are strings (objects) in the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Several columns are of object type, which means that either text or Nan values are present.\n",
    "def print_object_column_info(df):\n",
    "    \"\"\"\n",
    "    Print column data types and the number of object columns.\n",
    "    \"\"\"\n",
    "    print(big_df.dtypes, \"{} object columns present\". format(\n",
    "        len(big_df.select_dtypes(include=object).count())))\n",
    "\n",
    "\n",
    "print_object_column_info(big_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.select_dtypes(include=object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert year feature to numeric\n",
    "big_df.loc[:, 'Year'] = np.int64(big_df.Year)\n",
    "print_object_column_info(big_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: We notice that their are periods in the ALL_COHORT_ columns and numbers encoded as strings like \"GE95\" in the ALL_RATE_ column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.ALL_COHORT_.describe(), big_df.ALL_RATE_.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_nonconvertible_items(t: pd.Series):\n",
    "    \"\"\"\n",
    "    Print items in a series that cannot be trivially converted to a number. \n",
    "    E.g. '120' can be converted, but '.' or 'LE50' cannot.\n",
    "    \"\"\"\n",
    "\n",
    "    from collections import Counter\n",
    "    ret = []\n",
    "    for i in t:\n",
    "        try:\n",
    "            tmp = np.int64(i)\n",
    "        except:\n",
    "            ret += [i]\n",
    "    return Counter(ret)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gather_nonconvertible_items(\n",
    "    big_df.ALL_COHORT_), gather_nonconvertible_items(big_df.ALL_RATE_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number-like string entry observations\n",
    "* The ALL_COHORT_ column has 2913 rows with a '.'\n",
    "* THe ALL_RATE_ column has numbers given as ranges, numbers with GE,LE,LT,GT prefixes, and also 'PS'.\n",
    "* The codebook explains that these are to conceal specifics when it would give us the ability to identify individual students. The 'PS' specifically means that the cohort had 5 or fewer students in it.\n",
    "\n",
    "### Decisions\n",
    "* Drop the ALL_COHORT_ rows because it is only 1.4% of the data. We later decide to estimate these numbers from the Directory dataset, which states the size of the schools.\n",
    "* Drop the ALL_RATE_ rows that have 'PS' and convert the rest to the average meaning of the term. E.g. GT50 => 75, LT50 => 25, 88-92 => 90."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out number of schools in each year with 5 or fewer students in cohort.\n",
    "for df in dfs: \n",
    "    [print(sum(df[col] == 'PS')) for col in df.columns if col.startswith('ALL_RATE')]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where ALL_COHORT_ == '.'\n",
    "instances_after_drop = len(big_df) - 2913\n",
    "# Reindex the dataframe because their are duplicate indexes\n",
    "big_df.index = list(range(len(big_df)))\n",
    "big_df.drop(big_df[big_df.ALL_COHORT_ == '.'].index, axis=0, inplace=True)\n",
    "assert len(big_df) == instances_after_drop\n",
    "print(\"Number of instances after this drop\", len(big_df))\n",
    "# Can convert ALL_COHORT_ column to numeric now\n",
    "big_df.loc[:,'ALL_COHORT_'] = np.int64(big_df.ALL_COHORT_.values)\n",
    "big_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where ALL_RATE_ == 'PS'\n",
    "print(\"Dropping\", len(big_df[big_df.ALL_RATE_ == 'PS']))\n",
    "big_df.drop(big_df[big_df.ALL_RATE_ == 'PS'].index, axis=0, inplace=True)\n",
    "print(\"Number of instances after this drop\", len(big_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to convert ranges given in ALL_RATE_ column to a trivially convertible string \n",
    "def conv_range_to_numeric_string(t: str):\n",
    "    \"\"\"Take in a numeric range given as a string, e.g. \"10-20\" and return the midpoint as a string.\"\"\"\n",
    "    vals = t.split(\"-\")\n",
    "    if len(vals) == 2:\n",
    "        val1, val2 = float(vals[0]), float(vals[1])\n",
    "        new_val = val1 / 2.0 + val2 / 2.0\n",
    "        return str(new_val)\n",
    "    else:\n",
    "        # If a range with a dash in it is not found, return original string unchanged.\n",
    "        return t\n",
    "\n",
    "assert conv_range_to_numeric_string('95-95') == '95.0'\n",
    "assert conv_range_to_numeric_string('105-110') == '107.5'\n",
    "assert conv_range_to_numeric_string('90') == '90'\n",
    "\n",
    "def strip_prefixed_string(t: str):\n",
    "    \"\"\"\n",
    "    Convert prefixed numbers to a string of a number in the midpoint of their range \n",
    "    \"\"\"\n",
    "    if t.startswith('GT'):\n",
    "        t = t.removeprefix('GT')\n",
    "        t = float(t)\n",
    "        t = sum([t, 100.0])/2.0\n",
    "        return str(t)\n",
    "    elif t.startswith('GE'):\n",
    "        t = t.removeprefix('GE')\n",
    "        t = float(t)\n",
    "        t = sum([t, 100.0])/2.0\n",
    "        return str(t)\n",
    "    elif t.startswith('LT'):\n",
    "        t = t.removeprefix('LT')\n",
    "        t = float(t)\n",
    "        t = sum([t, 0])/2.0\n",
    "        return str(t)\n",
    "    elif t.startswith('LE'):\n",
    "        t = t.removeprefix('LE')\n",
    "        t = float(t)\n",
    "        t = sum([t, 0])/2.0\n",
    "        return str(t)\n",
    "    # If one of the prefixes is not found, return original string unchanged\n",
    "    return t\n",
    "\n",
    "assert strip_prefixed_string('GE50') == '75.0'\n",
    "assert strip_prefixed_string('GT50') == '75.0'\n",
    "assert strip_prefixed_string('LE90') == '45.0'\n",
    "assert strip_prefixed_string('LT90') == '45.0'\n",
    "assert strip_prefixed_string('95-95') == '95-95'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.ALL_RATE_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the above functions on the series to produce a float64 series\n",
    "big_df.loc[:, 'ALL_RATE_'] = big_df.ALL_RATE_.map(strip_prefixed_string, na_action='ignore')\n",
    "big_df.loc[:, 'ALL_RATE_'] = big_df.ALL_RATE_.map(conv_range_to_numeric_string, na_action='ignore')\n",
    "big_df.loc[:, 'ALL_RATE_'] = pd.to_numeric(big_df.ALL_RATE_.tolist()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.ALL_RATE_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore distributions, correlations, outliers of numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(big_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "* All graduation rates varies from 0 to 100, which matches expectation\n",
    "* Schools are not evenly distributed across states. \n",
    "* Outlier 1 ALL_COHORT_: For two schools 2017 and 2018, there are class size outliers of > 10000 students all others < 5000 students.\n",
    "* Outlier 2 LEAID and NCESSH: For the last two years, there are new school district (LEAID) and school id (NCESSCH) outside the range of the others. \n",
    "* Outlier 3 FIPST: There is a state code higher than 60, with all of its graduation rates higher than 20%.\n",
    "* Outlier 4 FIPST: There is one state code, higher than 50, only seen in the last two years of data.\n",
    "* Outlier 5 LEAID: There is one school district with all graduation rations >= 25%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier 1 - large cohort sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_school_indexes = big_df.ALL_COHORT_ > 5000\n",
    "big_df.loc[large_school_indexes,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision: Based on google search, the graduating classes are closer to 100-200 than the extremely large sizes reported.\n",
    "We drop these schools since they are called into question. Note that we could impute them with the mean school size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.drop(big_df[large_school_indexes].index,axis=0,inplace=True)\n",
    "big_df.ALL_COHORT_.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers 2, 3, 4, 5  - new school identifers in 2017 and 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.query('FIPST == 72 and NCESSCH > 6E11 and Year > 2016')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: New Puerto Rico school additions in 2017, either newly created or newly included in the data gathering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 405 Puerto Rico instances added for 2017 and 2018 that have graduation rates between 25 and 97%.\n",
    "all_puerto_rico_schools = big_df[big_df.STNAM == 'PUERTO RICO']\n",
    "puerto_rico_schools = big_df[big_df.LEAID > 7E6]\n",
    "assert(len(all_puerto_rico_schools) == len(puerto_rico_schools))\n",
    "puerto_rico_schools.Year.describe(), puerto_rico_schools.ALL_RATE_.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new pairplot now that the outliers have been investigated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(big_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: There is a group of large schools in the 3900-5000 cohort size range that are in the same state and school district. This outlier is the Electronic Classroom Of Tomorrow in Ohio. It has a below average graduation rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.query('ALL_COHORT_ > 3200').ALL_RATE_.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary statistics for cohort size and graduation rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.select_dtypes(include=np.number)[['ALL_COHORT_','ALL_RATE_']].describe()\n",
    "f, (ax, bx) = plt.subplots(2)\n",
    "plt.subplot(211)\n",
    "plt.title('Number of students in cohort')\n",
    "sns.boxplot(big_df.ALL_COHORT_,orient='horiz')\n",
    "plt.subplot(212)\n",
    "plt.title('Percentage that graduated')\n",
    "sns.boxplot(big_df.ALL_RATE_,orient='horiz')\n",
    "plt.tight_layout(pad=2)\n",
    "big_df[['ALL_COHORT_','ALL_RATE_']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which schools have < 15% graduation rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_25_percent_graduation = big_df.query('ALL_RATE_ < 25').NCESSCH.unique()\n",
    "print(len(under_25_percent_graduation), \"unique schools with less than 25 percent graduation rate between 2010-2018\")\n",
    "print(\"They are spread across\", big_df.query('NCESSCH in @under_25_percent_graduation').STNAM.unique().size, \"states\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Low performing schools are found distributed across 47 states in the nation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check whether there are graduation rate patterns by state or school district "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.plot.scatter(x='LEAID',y='ALL_RATE_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.plot.scatter(x='FIPST',y='ALL_RATE_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are right-shifted graduation rate distributions at state codes around 15,31,38,50,72"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical column analysis\n",
    "* Check whether state names map one-to-one with FIPST \n",
    "* Determine which features uniquely identify a school and which do not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fipst_to_stnam_dict(df):\n",
    "    \"\"\"\n",
    "    Verify that state codes match state names in a one-to-one fashion. \n",
    "    Return dictionary mapping FIPST to STNAM.\n",
    "    \"\"\"\n",
    "    fipst_to_name = {}\n",
    "    for fipst, name in zip(df.FIPST,df.STNAM):\n",
    "        if fipst in fipst_to_name:\n",
    "            try:\n",
    "                assert name == fipst_to_name[fipst]\n",
    "            except:\n",
    "                print(\"found name {} for fipst {} but {} was in dictionary already\".format(name,fipst,fipst_to_name[fipst]))\n",
    "        else:\n",
    "            fipst_to_name[fipst] = name\n",
    "    return fipst_to_name\n",
    "\n",
    "_ = create_fipst_to_stnam_dict(big_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obversation: Bureau of Indian Affairs was renamed to Bureau of Indian Education in 2006 and some schools were still using the old name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename BUREAU OF INDIAN AFFAIRS to BUREAU OF INDIAN EDUCATION\n",
    "indian_affairs_rows = big_df.query(\"STNAM.str.contains('INDIAN AFFAIRS')\").index\n",
    "big_df.loc[indian_affairs_rows,'STNAM'] = 'BUREAU OF INDIAN EDUCATION' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dictionary mapping state code to state name for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fipst_to_name = create_fipst_to_stnam_dict(big_df)\n",
    "print(len(fipst_to_name.keys()))\n",
    "sorted(fipst_to_name.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check whether state and school name are unique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The state and local school names are not unique. Any value over 9, which is the number of years studied, \n",
    "# indicates there were two schools with the same name for at least one year.\n",
    "mask_non_unique_names = big_df[['STNAM','SCHNAM']].value_counts().values > 9\n",
    "big_df[['STNAM','SCHNAM']].value_counts()[mask_non_unique_names]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: We have to use the NCESSCH to identify schools since it is the only unique identifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save multi-year graduation rate dataframe to file for future merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.to_csv('cleaned_mega_grad_rate_frame.csv.bak',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c763b49a4e9e1724a59991e53401f9a884eb20b0636088ef4cedf965df153b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
